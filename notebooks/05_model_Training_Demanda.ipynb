{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis Exploratorio de Datos - Demanda Energética Cuba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  fecha   año  mes  dia  dia_semana  es_fin_semana  \\\n",
      "0   2022-12-30 08:29:00  2022   12   30           4              0   \n",
      "1   2022-12-23 10:33:00  2022   12   23           4              0   \n",
      "2   2022-12-17 08:56:00  2022   12   17           5              1   \n",
      "3   2022-12-14 08:42:00  2022   12   14           2              0   \n",
      "4   2022-12-13 08:46:00  2022   12   13           1              0   \n",
      "..                  ...   ...  ...  ...         ...            ...   \n",
      "691 2025-05-05 09:10:00  2025    5    5           0              0   \n",
      "692 2025-05-03 08:39:00  2025    5    3           5              1   \n",
      "693 2025-05-02 11:58:00  2025    5    2           4              0   \n",
      "694 2025-05-01 11:50:00  2025    5    1           3              0   \n",
      "695 2025-05-04 11:00:00  2025    5    4           6              1   \n",
      "\n",
      "     demanda_maxima  disponibilidad_total  afectacion_predicha  \\\n",
      "0            2600.0                3109.0                  NaN   \n",
      "1            2700.0                2713.0                 60.0   \n",
      "2            2730.0                2815.0                  NaN   \n",
      "3            2780.0                2583.0                267.0   \n",
      "4            2750.0                2474.0                346.0   \n",
      "..              ...                   ...                  ...   \n",
      "691          3400.0                1790.0               1680.0   \n",
      "692          3400.0                2053.0               1417.0   \n",
      "693          3350.0                2014.0               1406.0   \n",
      "694          3150.0                2035.0               1185.0   \n",
      "695          3400.0                2053.0               1417.0   \n",
      "\n",
      "     deficit_predicho  ...  plantas_mantenimiento  mw_limitacion_termica  \\\n",
      "0                 NaN  ...                      2                  348.0   \n",
      "1                 NaN  ...                      2                  336.0   \n",
      "2                 NaN  ...                      2                  371.0   \n",
      "3               197.0  ...                      2                  309.0   \n",
      "4               276.0  ...                      2                  209.0   \n",
      "..                ...  ...                    ...                    ...   \n",
      "691            1610.0  ...                      5                  413.0   \n",
      "692            1347.0  ...                      3                  488.0   \n",
      "693            1336.0  ...                      3                  518.0   \n",
      "694            1115.0  ...                      3                  399.0   \n",
      "695            1347.0  ...                      4                  413.0   \n",
      "\n",
      "     mw_motores_problemas  horas_afectacion  max_afectacion_mw  deficit_real  \\\n",
      "0                   800.0               NaN                NaN        -509.0   \n",
      "1                   846.0               NaN                NaN         -13.0   \n",
      "2                   848.0               NaN              177.0         -85.0   \n",
      "3                   880.0               3.5              462.0         197.0   \n",
      "4                   872.0               1.5              196.0         276.0   \n",
      "..                    ...               ...                ...           ...   \n",
      "691                 610.0              24.0             1450.0        1610.0   \n",
      "692                 577.0              24.0             1683.0        1347.0   \n",
      "693                 872.0              24.0             1337.0        1336.0   \n",
      "694                 558.0              24.0             1587.0        1115.0   \n",
      "695                 573.0               NaN             1682.0        1347.0   \n",
      "\n",
      "     margen_seguridad  eficiencia_07am  utilizacion_07am   tipo_dia  \n",
      "0               509.0        85.558057         65.789474    Viernes  \n",
      "1                13.0        86.251382         79.487179    Viernes  \n",
      "2                85.0        86.678508         76.229508     Sábado  \n",
      "3              -197.0        85.172280         83.636364  Miércoles  \n",
      "4              -276.0        83.185125         88.435374     Martes  \n",
      "..                ...              ...               ...        ...  \n",
      "691           -1610.0       103.631285        146.900270      Lunes  \n",
      "692           -1347.0        83.779834        157.558140     Sábado  \n",
      "693           -1336.0        84.409136        158.823529    Viernes  \n",
      "694           -1115.0        97.542998        123.425693     Jueves  \n",
      "695           -1347.0        89.624939        138.586957    Domingo  \n",
      "\n",
      "[696 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "    \"\"\"Carga y prepara los datos iniciales\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convertir fecha a datetime\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'])\n",
    "    \n",
    "    # Crear variables derivadas adicionales\n",
    "    df['deficit_real'] = df['demanda_maxima'] - df['disponibilidad_total']\n",
    "    df['margen_seguridad'] = df['disponibilidad_total'] - df['demanda_maxima']\n",
    "    df['eficiencia_07am'] = df['disponibilidad_07am'] / df['disponibilidad_total'] * 100\n",
    "    df['utilizacion_07am'] = df['demanda_07am'] / df['disponibilidad_07am'] * 100\n",
    "    \n",
    "    # Categorizar días\n",
    "    df['tipo_dia'] = df['dia_semana'].map({\n",
    "        0: 'Lunes', 1: 'Martes', 2: 'Miércoles', 3: 'Jueves',\n",
    "        4: 'Viernes', 5: 'Sábado', 6: 'Domingo'\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "file_path = '../data/processed/cleaned_energy_data.csv'\n",
    "df = load_and_prepare_data(file_path)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables que vas a usar como entrada (features)\n",
    "features = [\n",
    "    'disponibilidad_total', 'disponibilidad_07am', \n",
    "    'demanda_07am', 'deficit_real', 'margen_seguridad', \n",
    "    'eficiencia_07am', 'utilizacion_07am', 'dia_semana'\n",
    "]\n",
    "\n",
    "# Variable a predecir\n",
    "target = 'demanda_maxima'\n",
    "\n",
    "# X = entrada, y = salida\n",
    "X = df[features]\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(542, 8) (542,)\n",
      "(137, 8) (137,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Alternativamente, para un simple train-test split:\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X.iloc[:train_size], X.iloc[train_size:]\n",
    "y_train, y_test = y.iloc[:train_size], y.iloc[train_size:]\n",
    "y_train = y_train[~y_train.isna()]\n",
    "\n",
    "# Combina X_train e y_train\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Elimina cualquier fila con NaN en features o target\n",
    "train = train.dropna()\n",
    "\n",
    "# Divide de nuevo\n",
    "X_train = train.drop(columns=target)\n",
    "y_train = train[target]\n",
    "\n",
    "\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "test = test.dropna()\n",
    "X_test = test.drop(columns=target)\n",
    "y_test = test[target]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - MAE: 101.92 | RMSE: 117.88 | R2: 0.502 | MAPE: 3.13%\n",
      "Gradient Boosting - MAE: 88.55 | RMSE: 102.88 | R2: 0.620 | MAPE: 2.72%\n",
      "SVR - MAE: 272.43 | RMSE: 300.75 | R2: -2.244 | MAPE: 8.34%\n",
      "Ridge - MAE: 0.00 | RMSE: 0.00 | R2: 1.000 | MAPE: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'SVR': SVR(),\n",
    "    'Ridge': Ridge()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # MAPE requiere que y_test no tenga ceros\n",
    "    try:\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    except:\n",
    "        mape = None\n",
    "\n",
    "    results[name] = {\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "\n",
    "    print(f\"{name} - MAE: {mae:.2f} | RMSE: {rmse:.2f} | R2: {r2:.3f} | MAPE: {mape:.2%}\" if mape is not None else\n",
    "          f\"{name} - MAE: {mae:.2f} | RMSE: {rmse:.2f} | R2: {r2:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Buscando mejores parámetros para: Random Forest\n",
      "Random Forest ✅ Best params: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Random Forest - MAE: 101.92 | RMSE: 117.88 | R2: 0.502 | MAPE: 3.13%\n",
      "🔍 Buscando mejores parámetros para: Gradient Boosting\n",
      "Gradient Boosting ✅ Best params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Gradient Boosting - MAE: 81.94 | RMSE: 96.11 | R2: 0.669 | MAPE: 2.51%\n",
      "🔍 Buscando mejores parámetros para: SVR\n",
      "SVR ✅ Best params: {'C': 1.0, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "SVR - MAE: 0.05 | RMSE: 0.05 | R2: 1.000 | MAPE: 0.00%\n",
      "🔍 Buscando mejores parámetros para: Ridge\n",
      "Ridge ✅ Best params: {'alpha': 0.1}\n",
      "Ridge - MAE: 0.00 | RMSE: 0.00 | R2: 1.000 | MAPE: 0.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'max_depth': [3, 5]\n",
    "    },\n",
    "    'SVR': {\n",
    "        'C': [1.0, 10.0],\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'alpha': [0.1, 1.0, 10.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=5)  # Mejor para datos temporales\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"🔍 Buscando mejores parámetros para: {name}\")\n",
    "    grid = GridSearchCV(model, param_grids[name], cv=cv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "\n",
    "    best_models[name] = {\n",
    "        'Best Estimator': best_model,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R2': r2,\n",
    "        'MAPE': mape\n",
    "    }\n",
    "\n",
    "    print(f\"{name} ✅ Best params: {grid.best_params_}\")\n",
    "    print(f\"{name} - MAE: {mae:.2f} | RMSE: {rmse:.2f} | R2: {r2:.3f} | MAPE: {mape:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
